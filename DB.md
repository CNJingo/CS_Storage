# DB


### DB는 데이터를 어떻게 저장해놓을까
<details>
   <summary> 자세히 보기 </summary>
 
 <br>

   우리가 DB에서 데이터를 조회하면 테이블 구조의 형태의 데이터를 만나게 될 것이다. 하지만 결국 이 또한 table에 대한 메타데이터와 로우데이터가 만나서 논리적으로 우리에게 테이블이라는 형태로 데이터가 보여지는 것이다.



   mysql에서  `SHOW VARIABLES LIKE 'datadir';` 이라는 명령어를 치면 메타데이터와 데이터가 존재하는 파일의 위치를 알 수 있다. 여기서 확장자명이 .frm인 것은 테이블의 포맷을 담고 있고 확장자 명이 .ibd인 것은 테이블의 데이터들을 담고 있다.



   DB는 기본적으로 트리형태로 데이터를 관리하고 있다. 일반적으로 B tree라는 것으로 데이터를 관리하고 있다. 

   <img width="1963" alt="스크린샷 2022-06-27 오전 1 03 39" src="https://user-images.githubusercontent.com/55564829/175823167-acd8aeaf-196b-4553-9448-b8efd39b4dfc.png">


   리프노드를 데이터 페이지라고 부르는데 이 데이터 페이지들이 실질적인 디비의 데이터들을 담고 있다. B tree는 clustered 인덱스로 구성되어 있으며 clustered 인덱스로 구성되어 있다는 것은 즉 데이터가 순차적으로 저장되어 있다는 것이다. 



   이러한 구조에서는 데이터를 찾아가는 과정에 있어서 full table scan이 필요 없이 바로 원하는 데이터 페이지를 찾아갈 수 있다는 장점이 있다. 즉 엄청나게 느린 작업인 disk I/O를 줄여서 데이터를 찾는 작업을 최적화 시킨 것이다.

</details>

### DB transaction이란?
<details>
   <summary> 자세히 보기 </summary>
 
 <br>
   DB transaction이란 데이터베이스의 일관성을 유지하기 위해서 완전히 실행되거나 완전히 실패해야하는 작업을 얘기한다.

   트랜잭션의 내용은 script형태로 되어있다. 절차적으로 작업들을 순차적으로 실행하는 것이다. 

   이 작업들의 시작부터 끝을 하나의 단위로 생각하고 이 하나의 단위는 온전하게 실행되어야지만 commit하는 것이다.

   이러한 특성을 원자성이라고 부른다.

   하나의 단위에 속해있는 작업이 하나라도 실패하면 모든 작업을 되돌리는 rollback작업이 반드시 필요하다.

   트랜잭션의 일관성이란 데이터 베이스를 만들때 미리 정의해놓은 일련의 규칙에 대해서 이 규칙을 위배하는 데이터는 받아들이지 않는 것을 의미한다.

   데이터 베이스는 트랜잭션에 의해서 변경이 야기될 때 바로 그 변경이 디스크에 반영되는 것이 아니라 메모리에 반영이된다(inno DB 스토리지 엔진같은 경우 버퍼풀에 해당된다). 그래서 디비 롤백이 된다는 것은 매모리에 저장되어 있던 변경된 데이터들을 지우는 것이다.

   트랜잭션이 완료되면 메모리 내용을 디스크에 반영해야되는데 이 것을 commit이라고 부른다.

   데이터베이스에는 격리성이라는 특징이 있는데 이는 트랜잭션이 동시에 발생했을때 정해진 규칙에 따라서 얼만큼 영향을 받게할 것인지를 결정하는 것이다.

   그렇다면 정해진 규칙이란 무엇이냐? 바로 여기서 격리 레벨의 개념이 나온다.

   격리 레벨에는 총 4가지가 있다. READ_UNCOMMITED, READ_COMMITTED, REPEATABLE_READ, SERIALIZABLE. (격리 수준이 낮은 순부터 나열한 것이다)

   격리 수준은 높아질수록 동시성을 제한하기 때문에 성능이 저하되는 이슈를 가지고 있다. 하지만 보안성이나 데이터 privacy는 낮아질 수 있다.

   일관된 읽기를 지원하기 위해서 잠금을 걸지 않고 읽기 작업을 수행할 수 있다. 잠금을 걸지 않는 다는 의미는 읽기 작업이 다른 트랜잭션의 잠금을 기다리지 않고 읽기 작업이 가능 즉 동시에 여러개의 트랜잭션이 작동할 수 있다는 것이다. (SERIALIZABLE에서는 불가능)

   여기서는 격리수준에 따라서 어떤 데이터를 읽어오느냐가 달라지게 된다.

   READ_UNCOMMITED는 커밋되지 않는 dirty데이터를 읽어온다.

   READ_COMMITED는 커밋된 데이터만을 읽어온다.

   REPEATABLE_READ는 커밋된 데이터만을 읽어오는 것은 물론 한 트랜잭션 내에서 같은 row에 대해서 read를 반복적으로 진행할때 항상 같은 데이터를 가져온다는 것을 보장해준다. 

      
</details>


### 데이터베이스 이상 현상이란?
<details>
   <summary> 자세히 보기 </summary>
 
 <br>
   데이터베이스의 정규화가 제대로 되어 있지 않았을때 의도한 대로 데이터 조작이 안되는 현상을 말한다.

   데이터베이스가 제대로 정규화 되어 있지 않다면 중복 데이터들이 존재할 가능성이 높고 이는 삽입, 수정, 삭제를 할때 문제를 발생시킬 수 있다는 점이다.

   삽입에 관련해서는 당장 존재하지 않는 데이터를 넣어야하는 오류가 발생할 수가 있다. 예를 들어 학생이 수강하고 있는 강의를 넣고 싶다고 가정할때 신규 학생이 들어왔지만 아직 수강중인 강의가 없을 때 이를 임의로 채워넣어서 데이터를 삽입해야 하는 상황이 발생한다. 이럴 경우 학생의 학적정보와 강의 정보를 분리한다면 해결할 수 있는 문제일 것이다.

   삭제에 관련해서는 내가 의도하지 않은 다른 row까지 삭제할 수 있다는 위험이 있습니다. 이는 중복된 데이터가 존재하기 떄문에 특정 칼럼을 조건으로 건다면 해당 칼럼을 중복으로 가지고 있는 여러 row들이 삭제될 것입니다.

   업데이트는 중복된 데이터가 존재하면 그중 하나의 데이터만 업데이트 됐을시에 데이터들 사이에 불일치가 발생할 수 있습니다.
   
   데이터 베이스의 정규화는 하지만 반드시 필요한 것은 아닙니다. 상황에 따라서 불필요한 경우가 생길 수도 있습니다. 
   
   자주 Select되는 데이터에 대해서 계속해서 조인이 필요한 상황이라고 한다면 서로 다른 disk block에 있는 데이터를 가져오기 위해서 성능이 느린 disk i/o가 발생할 것이고 이는 성능 저하를 일으킬 수 있습니다. 
   
   이럴때 자주 읽어져 오는 데이터에 대해서 비정규화를 하여 조인을 하지 않고도 데이터를 가져올 수 있게끔 하는 전략이 필요할때도 있습니다. 정규화라는 것은 그래서 상황에 따라 필요할 수도 필요하지 않을 수도 있습니다.


   
   
   
   
   
</details>

### optimistic locking vs pessmistic locking
<details>
   <summary> 자세히 보기 </summary>
 
 <br>
   일반적으로 DB transaction isolation은 read에 대한 consistency에 관한 내용입니다. 하지만 db update에 관해서도 같은 row에 대한 수정이 동시에 일어날때 우리는 이를 관리할 필요성이 있습니다. 그 방법으로 첫번째는 optimistic locking이 있습니다. 
   
   optimistic locking의 핵심은 versioning입니다. db update마다 버전을 집어넣어서 commit을 할때 where조건에 이전 버전을 넣어줌으로써 이전 버전이 commit되어 있는 상태인지를 체크합니다. 만약 이전에 다른 commit이 버전을 올려놓았다면 우리는 그 버전보다 1을 높여서 다시 commit을 하게 됩니다. 이로써 우리는 동시에 발생한 update에서 두번쨰 update가 첫번쨰 update내용을 overwrite하는 것을 방지할 수 있습니다.
   
   pessimistic locking은 db update하는 동안 lock을 걸어서 그 누구도 접근할 수 없게 하는 기법입니다. 이는 이론상 제일 안전하지만 deadlock과 같은 위험성을 내포하고 있습니다. 이렇게 보면 무조건 optimistic locking을 사용하는게 좋지 않나라는 생각이 들 수 있습니다.
   
   optimistic locking은 주로 충돌이 많이 예상되지 않는 상황일떄 사용합니다. 왜냐하면 충돌이 많이 발생하는 환경에서는 트랜잭션이 중단되는 것을 해결하는데 비용이 더 많이 소모되기 떄문입니다.
   
   
</details>

### innodb 버퍼풀
<details>
   <summary> 자세히 보기 </summary>
   
   
 <br>
 
   버퍼풀은 innodb 스토리지 엔진의 핵심 부분으로 디스크의 데이터 파일이나 인덱스 정보를 메모리공간에 캐시해 두는 공간이다. 또는 쓰기 작업을 지연시켜서 일괄 작업으로 처리할 수 있게 해주는 버퍼 역할도 할 수 있다.
   
   쓰기 작업은 랜덤한 디스크 작업을 유발할 수 있는데 버퍼풀에 모아서 한번에 처리하면 랜덤 디스크 작업 횟수를 줄일 수 있다.
   
   innodb 구조는 LRU리스트와 플러쉬리스트 그리고 프리리스트 3가지 자료구조로 구성되어 있다.
   
   LRU는 조금 더 세부적으로 들어가면 LRU와 MRU로 나뉜다. MRU가 더 최신에 참조된 데이터이며 LRU영역은 조금 오래된 데이터 영역이라고 생각하면 된다.
   
  스토리지 엔진이 데이터를 찾는 과정은 다음과 같다.
   
   1. 필요한 레코드가 버퍼 풀에 있는지 확인
   2. 디스크에서 필요한 데이터 파일을 버퍼 풀에 적재 그리고 적재된 페이지에 대한 포인터를 LRU헤더에 추가
   
   3. LRU 헤더부분에 적재된 데이터가 실제로 읽히면 MRU 헤더 부분으로 이동
   
   4. 버퍼 풀에 있는 데이터는 접근이 오래동안 되지 않으면 점점 리스트에서 밀려나서 결국 제거된다. 만약 참조가 된다면 다시 MRU 헤더 부분으로 옮겨진다.
   
   5. 필요한 데이터가 자주 접근되면 해당 페이지의 인덱스 키를 어댑티브 해시 인덱스에 추가한다.
   
   플러시 리스트는 디스크와 동기화 되지 않은 데이터를 가진 데이터 페이지를 관리한다. 디스크에서 읽어 들어온 뒤에 데이터가 변경이 되면 플러시 리스트 관리 대상이 되고 특정한 시간이 되면 디스크로 시록돼야 한다.
   
   innodb는 데이터 변경 내용을 리두 로그에 기록하고 버퍼 풀의 데이터 페이지도 변경을 시도하는데 리두로그와 버퍼풀의 내용은 반드시 일치하지 않을 수 있다. 리두 로그 내용이 디스크에 기록 됐다고 버퍼 풀 데이터가 디스크에 기록됐음을 보장하지 않는다.
   
   우리는 보통 변경이 발생하지 않은 데이터를 클린 페이지라고 명명하고 변경이 발생한 데이터를 더티 페이지라고 부른다.

   더티 페이지는 플러시 리스트에 저장되어 있다가 특정한 시간마다 플러시를 호출하여 디스크로 동기화 작업을 진행한다. 그렇게 하면 리두 로그 공간이 비워지게 된다.
   
  
   
</details>

### flush와 commit의 차이점
<details>
   <summary> 자세히 보기 </summary>
   
   
 <br>
   
   flush는 현재 메모리상에 있는 오브젝트의 상태를 데이터베이스와 동기화하는 행위이다. 하지만 그것은 트랜잭션을 커밋하지 않는다. 
   
   그렇기 때문에 만약 flush를 콜한 이후에 exception이 발생하면 트랜잭션은 롤백된다. 
   
   만약 사용자가 작은 청크의 데이터를 flush해주지 않고 큰 데이터를 한번에 commit하려고 한다면 OutOfMemoryException이 발생할 수 있다. flush를 해줘야지만 메모리에 있는 변경사항을 지우고 디비쪽에 변경사항을 저장할 수 있기 때문이다.

   반면 commit은 데이터 베이스에 데이터를 영구적으로 저장하는 행위이다. 만약 사용자가 commit()을 성공적으로 한다면 더이상 롤백할 방법이 존재하지 않는다.
 

  
   
</details>
